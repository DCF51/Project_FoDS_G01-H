# ==============================  Imports/Packages  ==============================
# standard packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
# data split and standardizing(/scaling)
from sklearn.model_selection import train_test_split, StratifiedKFold, \
    KFold  # je nachdem ob wir KFold brauchen, das weglassen
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
#the 4 learning models
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.tree import DecisionTreeClassifier
# for decision trees see: https://scikit-learn.org/stable/modules/tree.html
from sklearn.svm import SVC, NuSVC, LinearSVC
# for svm we have different methods see: https://scikit-learn.org/stable/modules/svm.html
# metrics
from sklearn.metrics import r2_score, mean_squared_error, roc_curve, confusion_matrix, auc
# Label encoder
from sklearn.preprocessing import LabelEncoder
# other
import warnings

warnings.filterwarnings('ignore')


# ==============================  Functions  ==============================

# Utility function to plot the diagonal line
def add_identity(axes, *line_args, **line_kwargs):
    identity, = axes.plot([], [], *line_args, **line_kwargs)

    def callback(axes):
        low_x, high_x = axes.get_xlim()
        low_y, high_y = axes.get_ylim()
        low = max(low_x, low_y)
        high = min(high_x, high_y)
        identity.set_data([low, high], [low, high])

    callback(axes)
    axes.callbacks.connect('xlim_changed', callback)
    axes.callbacks.connect('ylim_changed', callback)
    return axes


def evaluation_metrics(clf, y, X, ax, legend_entry='my legendEntry'):
    """
    compute multiple evaluation metrics for the provided classifier given the true labels
    and input features. Provides a plot of the roc curve on the given axis with the legend
    entry for this plot being specified, too.

    :param clf: classifier method
    :type clf: numpy array

    :param y: true class labels
    :type y: numpy array

    :param X: feature matrix
    :type X: numpy array

    :param ax: matplotlib axis to plot on
    :type legend_entry: matplotlib Axes

    :param legend_entry: the legend entry that should be displayed on the plot
    :type legend_entry: string

    :return: confusion matrix comprising the
             true positives (tp),
             true negatives  (tn),
             false positives (fp),
             and false negatives (fn)
    :rtype: four integers
    """

    # Get the label predictions
    y_test_pred = clf.predict(X)

    # Calculate the confusion matrix given the predicted and true labels
    tn, fp, fn, tp = confusion_matrix(y, y_test_pred).ravel()

    print(':) Successfully implemented the confusion matrix!')

    print('Confusion matrix:\n\t  |y_true = 0\t|y_true = 1')
    print('----------|-------------|------------')
    print('y_pred = 0|  ' + str(tn) + '\t\t|' + str(fn))
    print('y_pred = 1|  ' + str(fp) + '\t\t|' + str(tp))

    # Check for denominator of zero
    def safe_divide(numerator, denominator):
        return numerator / denominator if denominator != 0 else 0

    # Calculate the evaluation metrics
    precision = safe_divide(tp, (tp + fp))
    recall = safe_divide(tp, (tp + fn))
    f1_score = safe_divide((tp), (tp + (0.5 * (fn + fp))))
    specificity = safe_divide(tn, (tn + fp))
    accuracy = safe_divide((tp + tn), (tp + tn + fp + fn))

    # Get the roc curve using a sklearn function
    y_test_predict_proba = clf.predict_proba(X)
    fp_rates, tp_rates, _ = roc_curve(y, y_test_predict_proba[:,
                                         1])  # i want the predictioin probability for the class "1"

    # Calculate the area under the roc curve using a sklearn function
    roc_auc = auc(fp_rates, tp_rates)

    # Plot on the provided axis - feel free to make this plot nicer if
    # you want to.
    ax.plot(fp_rates, tp_rates, label='Fold {}'.format(legend_entry))

    return [accuracy, precision, recall, specificity, f1_score, roc_auc]


# ==============================  Import data  ==============================
data = pd.read_csv(
    filepath_or_buffer='~/Desktop/data/healthcare-dataset-stroke-data.csv',
    index_col='id',
    dtype={'gender': object, 'age': float, 'hypertension': bool, 'heart_disease': bool,
           'ever_married': object, 'work_type': object, 'Residence_type': object,
           'avg_glucose_level': float, 'bmi': float, 'smoking_status': object, 'stroke': bool}
)

# ==============================  Define datatypes  ==============================
# as categorical if needed
data['gender'] = pd.Categorical(data['gender'])
data['work_type'] = pd.Categorical(data['work_type'])
data['Residence_type'] = pd.Categorical(data['Residence_type'])
data['smoking_status'] = pd.Categorical(data['smoking_status'])

# change 'ever_married' to boolean
data['ever_married'] = data['ever_married'].map({'Yes': True, 'No': False})
data['ever_married'] = data['ever_married'].astype(bool)

# ==============================  Data description  ==============================
# Shape and meaning of dataframe -- df.info(), df.shape[], df.columns, df.head()
data.info()
print('There are ', data.shape[1], 'columns in the data.')
print('There are ', data.shape[0], 'rows in the data.')

# data.columns not necessary because already included in data.info()

# Datatypes -- df.info() and df.dtypes
# data.dtypes not necessary because already included in data.info()

# Missing Data -- df.isna().sum()
print('missing values:')
print(data.isna().sum())  ###bmi has 201 missing values
# Calculate the mean or median of the "bmi" feature
bmi_mean = data['bmi'].mean()
bmi_median = data['bmi'].median()
print(bmi_mean)
print(bmi_median)
# Replace the missing values with the mean or median
data['bmi'].fillna(bmi_mean, inplace=True)
print(data.isna().sum())

# Brief summary of extremes/means/medians -- df.describe()
print(data.describe())

# Check for duplicate rows -- df.duplicated()
print('sum of duplicated lines is:', data.duplicated().sum())  # marks all duplicates except the first occurence
# ==============================  Data manipulation  ==============================
# Identify the categorical (cat_cols), numerical features (num_cols) and boolean features (boolean_cols)
num_cols = ['age', 'avg_glucose_level', 'bmi']
cate_cols = ['gender', 'work_type', 'Residence_type', 'smoking_status']
boolean_cols = ['hypertension', 'heart_disease', 'ever_married', 'stroke']

# Convert boolean columns to integers (0 or 1)
data[boolean_cols] = data[boolean_cols].astype(int)

# This replaces the categorical columns with their corresponding encoded numerical values
label_encoder = LabelEncoder()
for col in cate_cols:
    data[col] = label_encoder.fit_transform(data[col])
    
# This helps that no more columns are created than before
columns_to_keep = num_cols + cate_cols + boolean_cols
data_e = data[columns_to_keep]

# ==============================  Data Visualization  ==============================

age_distribution = sns.histplot(x=data['age'], color='blue', bins=1, binwidth=1)
age_distribution.set(xlabel='Age', ylabel='Number of Patients', title='Age Distribution')
plt.grid(True)
age_distribution.set_axisbelow(True)
age_distribution.set_zorder(-1)

bmi_distribution = sns.histplot(x=data['bmi'], color='blue', bins=1, binwidth=1)
bmi_distribution.set(xlabel='BMI', ylabel='Number of Patients', title='BMI Distribution')
plt.grid(True)
bmi_distribution.set_axisbelow(True)
bmi_distribution.set_zorder(-1)

glucose_level_distribution = sns.histplot(x=data['avg_glucose_level'], color='blue', bins=1, binwidth=1)
glucose_level_distribution.set(xlabel='Average Glucose Level', ylabel='Number of Patients',
                               title='Glucose Level Distribution')
plt.grid(True)
glucose_level_distribution.set_axisbelow(True)
glucose_level_distribution.set_zorder(-1)

# ==============================  Feature selection  ==============================
# don't know what exactly to use here yettarget_variable_name', axis=1)  # Replace 'target_variable_name' with the actual name of your target variable


# ==============================  Data split  ==============================

X = data.copy().drop(columns='stroke')
y = data['stroke']

# ––––––––––––––––––––––––––––––  SStratified K-fold cross validator  ––––––––––––––––––––––––––––––
n_splits = 5
kfold = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)
accuracy_scores = []

# ----------------------------  Standardizing/Scaling  ---------------------------------
sc = StandardScaler()
# create copies like in the tutorial to avoid inplace operations

#Barplot Stroke/NoStroke
import pandas as pd
import matplotlib.pyplot as plt

# Assuming your dataset is stored in a DataFrame called 'df'
stroke_counts = data['stroke'].value_counts()

# Define colors for the bars
colors = ['steelblue', 'lightgray']

# Create a bar plot
plt.bar(stroke_counts.index, stroke_counts.values, color=colors)

# Add labels and title
plt.xlabel('Stroke')
plt.ylabel('Count')
plt.title('Number of People with and without Stroke')

# Add value labels on top of each bar
for i, count in enumerate(stroke_counts.values):
    plt.text(i, count, str(count), ha='center', va='bottom')

# Modify the legend labels and colors
legend_labels = ['No Stroke', 'Stroke']
legend_colors = [colors[0], colors[1]]

# Add a legend with modified labels, colors, and increased font size
plt.legend(handles=[plt.Rectangle((0, 0), 1, 1, color=color) for color in legend_colors],
           labels=legend_labels,
           fontsize='medium', frameon = False)
plt.xticks([])
# Display the plot
plt.show()

# –––––––––––––––––––––––––––––– Support Vector Machine ––––––––––––––––––––––––––––––
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import confusion_matrix
from sklearn.decomposition import PCA
from sklearn.metrics import ConfusionMatrixDisplay
from sklearn.svm import NuSVC
from sklearn.model_selection import GridSearchCV

# Counter to keep track of fold number
fold = 0

# Define the parameter grid
param_grid = {
    'nu': [0.05, 0.06, 0.07],
    'kernel': ['linear', 'rbf', 'poly'],
    'gamma': ['scale', 'auto'],
    'degree': [2, 3, 4]
}

# Create the NuSVC model
nusvc = NuSVC(random_state=42)

# Split the data into train and test sets
X_train_NuSVC = X.iloc[train_i]
y_train_NuSVC = y.iloc[train_i]
X_test_NuSVC = X.iloc[test_i]
y_test_NuSVC = y.iloc[test_i]

# Scale the training and test data
X_train_NuSVC_sc = sc.fit_transform(X_train_NuSVC)
X_test_NuSVC_sc = sc.transform(X_test_NuSVC)

# This creates an SVM classifier
clf_svm = NuSVC(nu=0.07)
clf_svm.fit(X_train_NuSVC_sc, y_train_NuSVC)

# Prepare the performance overview data frame
df_performance_NuSVC = pd.DataFrame(columns=['fold', 'accuracy', 'precision', 'recall', 'specificity', 'F1', 'roc_auc'])

scoring_types = ['accuracy', 'precision', 'recall', 'f1']
 
for scoring_type in scoring_types:
    # Create the GridSearchCV object with the specific scoring type
    grid_search = GridSearchCV(estimator=nusvc, param_grid=param_grid, cv=5, scoring=scoring_type, refit=False)
    
    # Fit the GridSearchCV object to the data
    grid_search.fit(X_train_NuSVC_sc, y_train_NuSVC)
    
    # Get the best parameters and best score
    best_params = grid_search.best_params_
    best_score = grid_search.best_score_
    
    # Print the scoring type, best parameters, and best score
    print("Scoring Type:", scoring_type)
    print("Best Parameters:", best_params)
    print("Best Score:", best_score)
    print("---------------------")    
    
# Create the NuSVC model with the best parameters
nusvc = NuSVC(nu=0.07, degree=4, gamma='scale', kernel='poly')

# Fit the model to the training data
nusvc.fit
    
# Create the NuSVC model with the best parameters
#nusvc = NuSVC(nu=0.06, degree=2, gamma='auto', kernel='rbf')

# Fit the model to the training data
nusvc.fit(X_train_NuSVC_sc, y_train_NuSVC)

# Predict the labels for the test set
y_pred_NuSVC = nusvc.predict(X_test_NuSVC_sc)

# Calculate the confusion matrix
cm = confusion_matrix(y_test_NuSVC, y_pred_NuSVC)

# Create a ConfusionMatrixDisplay object and plot the confusion matrix
disp = ConfusionMatrixDisplay(confusion_matrix=cm)
disp.plot()

# Show the plot
plt.show()

#--------------ROC Curve--------------
from sklearn.metrics import roc_curve, precision_recall_curve, auc

# Fit the model to the training data
nusvc.fit(X_train_NuSVC_sc, y_train_NuSVC)

# Get the scores for the positive class
y_scores_NuSVC = nusvc.decision_function(X_test_NuSVC_sc)

# Compute the false positive rate, true positive rate, and threshold for the ROC curve
fpr, tpr, thresholds_roc = roc_curve(y_test_NuSVC, y_scores_NuSVC)

# Compute the precision, recall, and threshold for the precision-recall curve
precision, recall, thresholds_pr = precision_recall_curve(y_test_NuSVC, y_scores_NuSVC)

# Compute the area under the ROC curve
roc_auc = auc(fpr, tpr)

# Plot the ROC curve
plt.figure(figsize=(8, 6))
plt.plot(fpr, tpr, label='ROC Curve (AUC = %0.2f)' % roc_auc)
plt.plot([0, 1], [0, 1], 'r--', label='Random Classifier')
plt.xlim([0, 1])
plt.ylim([0, 1])
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('Receiver Operating Characteristic (ROC) Curve')
plt.legend()
plt.show()


#-----------
import pandas as pd
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score

# List to store performance metrics for each fold
results = []

# Perform grid search and cross-validation
for fold, (train_index, test_index) in enumerate(kfold.split(X, y)):
    X_train, X_test = X.iloc[train_index], X.iloc[test_index]
    y_train, y_test = y.iloc[train_index], y.iloc[test_index]
    
    # Standardize the data
    X_train_sc = sc.fit_transform(X_train)
    X_test_sc = sc.transform(X_test)

    # Create the NuSVC model with the best parameters
    nusvc = NuSVC(nu=0.07, degree=2, gamma='auto', kernel='rbf')

    # Fit the model to the training data
    nusvc.fit(X_train_sc, y_train)

    # Predict the labels for the test set
    y_pred = nusvc.predict(X_test_sc)

    # Calculate performance metrics
    accuracy = accuracy_score(y_test, y_pred)
    precision = precision_score(y_test, y_pred)
    recall = recall_score(y_test, y_pred)
    f1 = f1_score(y_test, y_pred)
    roc_auc = roc_auc_score(y_test, y_pred)

    # Append the results to the list
    results.append([fold, accuracy, precision, recall, f1, roc_auc])

# Create a DataFrame from the results list
df_performance = pd.DataFrame(results, columns=['fold', 'accuracy', 'precision', 'recall', 'F1', 'roc_auc'])

print(df_performance)
